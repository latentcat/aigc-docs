export const metadata = {
  title: 'Stable Diffusion æ¨¡å‹ç”Ÿæ€',
}


# Stable Diffusion æ¨¡å‹ç”Ÿæ€


<Authors names="ciaochaos" />

<Note>
  å°šæœªå®Œæˆï¼ŒæŒç»­æ›´æ–°
</Note>




### To Categorize

- Embeddings
- Dreambooth Checkpoint
- LoCon / LoHa / LyCORIS
- T2I Adapter
- Wonder 3D
- AnimateDiff
- LCM / LCM LoRA
- Consistency Decoder
- AnimateAnyone
- MagicAnimate



### Others


- DreamGaussion
- Stable Video Diffusion



## Original Stable Diffusion


[High-Resolution Image Synthesis with Latent Diffusion Models](https://arxiv.org/abs/2112.10752)


![](/assets/sd-ecology/original-sd.jpeg)


> æœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªå»å™ªçš„è¿‡ç¨‹ï¼Œåšäº†ä¸‰ä»¶äº‹æƒ…ï¼Œä¸€æ˜¯è®­ç»ƒäº†ä¸€ä¸ªä»å™ªå£°ä¸­æƒ³è±¡å›¾åƒçš„ç½‘ç»œï¼ˆUNetï¼‰ï¼ŒäºŒæ˜¯é€šè¿‡æ³¨æ„åŠ›æœºåˆ¶è®©æ–‡å­—å¼•å¯¼å»å™ªè¿‡ç¨‹ï¼ˆSpatial Trasformerï¼‰ï¼Œä¸‰æ˜¯æŠŠæ•´ä¸ªå»å™ªçš„è¿‡ç¨‹ä»åƒç´ ç©ºé—´è¿ç§»åˆ° Latent ç©ºé—´ï¼ˆé€šè¿‡ VAEï¼‰ï¼Œæ‰€ä»¥ Stable Diffusion åˆ†ç±»ä¸Šæ˜¯ä¸€ä¸ª LDM æ¨¡å‹ï¼ˆLatent Diffusion Modelï¼‰




## App


- AI Comic Factory
https://huggingface.co/spaces/jbilcke-hf/ai-comic-factory
- Try Emoji
https://huggingface.co/spaces/leptonai/tryemoji
- IllusionDiffusion
https://huggingface.co/spaces/AP123/IllusionDiffusion
- PixArt LCM
https://huggingface.co/spaces/PixArt-alpha/PixArt-LCM



## ControlNet

[Adding Conditional Control to Text-to-Image Diffusion Models](http://arxiv.org/abs/2302.05543)

* [lllyasviel/ControlNet: Let us control diffusion models!](https://github.com/lllyasviel/ControlNet)
* [lllyasviel/ControlNet-v1-1-nightly: Nightly release of ControlNet 1.1](https://github.com/lllyasviel/ControlNet-v1-1-nightly)
* [ControlNet in ğŸ§¨ Diffusers](https://huggingface.co/blog/controlnet)
* [ControlNet](https://huggingface.co/docs/diffusers/api/pipelines/controlnet)
* [Train your ControlNet with diffusers](https://huggingface.co/blog/train-your-controlnet)
* [ControlNet](https://huggingface.co/docs/diffusers/training/controlnet)



## LoRA

[LoRA: Low-Rank Adaptation of Large Language Models](http://arxiv.org/abs/2106.09685)




## IP Adapter

[IP-Adapter: Text Compatible Image Prompt Adapter for Text-to-Image Diffusion Models](http://arxiv.org/abs/2308.06721)

* [IP-Adapter å®˜ç½‘](https://ip-adapter.github.io/)
* [IP-Adapter GitHub](https://github.com/tencent-ailab/IP-Adapter)
* [IP-Adapter Hugging Face](https://huggingface.co/h94/IP-Adapter)


## Style Aligned Generation

[[Style Aligned Image Generation å‚è€ƒ]]

[Style Aligned Image Generation via Shared Attention](http://arxiv.org/abs/2312.02133)

https://style-aligned-gen.github.io
https://github.com/google/style-aligned/blob/main/style_aligned_sdxl.ipynb

![](/assets/sd-ecology/style-aligned.png)


## MagicAnimate

* [MagicAnimate å®˜ç½‘](https://showlab.github.io/magicanimate/)
* [MagicAnimate GitHub](https://github.com/magic-research/magic-animate)
* [MagicAnimate Hugging Face Space](https://huggingface.co/spaces/zcxu-eric/magicanimate)


## MotionCtrl

[MotionCtrl: A Unified and Flexible Motion Controller for Video Generation](http://arxiv.org/abs/2312.03641)

* [MotionCtrl](https://wzhouxiff.github.io/projects/MotionCtrl/)
* [TencentARC/MotionCtrl](https://github.com/TencentARC/MotionCtrl)

![](/assets/sd-ecology/motion-ctrl.png)

<video width="100%" controls>
  <source src="/assets/sd-ecology/motion-ctrl.mp4" type="video/mp4" />
</video>






