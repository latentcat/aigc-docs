export const metadata = {
  title: 'Stable Diffusion æ¨¡å‹ç”Ÿæ€',
}


# Stable Diffusion æ¨¡å‹ç”Ÿæ€


ç¼–å†™ï¼š<Authors names={["ciaochaos", "zhaohan"]} />

<Note>
  å°šæœªå®Œæˆï¼ŒæŒç»­æ›´æ–°
</Note>




### To Categorize

- Embeddings
- Dreambooth Checkpoint
- LoCon / LoHa / LyCORIS
- T2I Adapter
- Wonder 3D
- AnimateDiff
- LCM / LCM LoRA
- Consistency Decoder
- AnimateAnyone
- MagicAnimate



### Others


- DreamGaussion
- Stable Video Diffusion



## Original Stable Diffusion


[High-Resolution Image Synthesis with Latent Diffusion Models](https://arxiv.org/abs/2112.10752)


![](/assets/sd-ecology/original-sd.jpeg)


> æœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªå»å™ªçš„è¿‡ç¨‹ï¼Œåšäº†ä¸‰ä»¶äº‹æƒ…ï¼Œä¸€æ˜¯è®­ç»ƒäº†ä¸€ä¸ªä»å™ªå£°ä¸­æƒ³è±¡å›¾åƒçš„ç½‘ç»œï¼ˆUNetï¼‰ï¼ŒäºŒæ˜¯é€šè¿‡æ³¨æ„åŠ›æœºåˆ¶è®©æ–‡å­—å¼•å¯¼å»å™ªè¿‡ç¨‹ï¼ˆSpatial Trasformerï¼‰ï¼Œä¸‰æ˜¯æŠŠæ•´ä¸ªå»å™ªçš„è¿‡ç¨‹ä»åƒç´ ç©ºé—´è¿ç§»åˆ° Latent ç©ºé—´ï¼ˆé€šè¿‡ VAEï¼‰ï¼Œæ‰€ä»¥ Stable Diffusion åˆ†ç±»ä¸Šæ˜¯ä¸€ä¸ª LDM æ¨¡å‹ï¼ˆLatent Diffusion Modelï¼‰




## App


- AI Comic Factory
https://huggingface.co/spaces/jbilcke-hf/ai-comic-factory
- Try Emoji
https://huggingface.co/spaces/leptonai/tryemoji
- IllusionDiffusion
https://huggingface.co/spaces/AP123/IllusionDiffusion
- PixArt LCM
https://huggingface.co/spaces/PixArt-alpha/PixArt-LCM



## ControlNet

[Adding Conditional Control to Text-to-Image Diffusion Models](http://arxiv.org/abs/2302.05543)

* [lllyasviel/ControlNet: Let us control diffusion models!](https://github.com/lllyasviel/ControlNet)
* [lllyasviel/ControlNet-v1-1-nightly: Nightly release of ControlNet 1.1](https://github.com/lllyasviel/ControlNet-v1-1-nightly)
* [ControlNet in ğŸ§¨ Diffusers](https://huggingface.co/blog/controlnet)
* [ControlNet](https://huggingface.co/docs/diffusers/api/pipelines/controlnet)
* [Train your ControlNet with diffusers](https://huggingface.co/blog/train-your-controlnet)
* [ControlNet](https://huggingface.co/docs/diffusers/training/controlnet)



## LoRA

[LoRA: Low-Rank Adaptation of Large Language Models](http://arxiv.org/abs/2106.09685)




## IP Adapter

[IP-Adapter: Text Compatible Image Prompt Adapter for Text-to-Image Diffusion Models](http://arxiv.org/abs/2308.06721)

* [IP-Adapter å®˜ç½‘](https://ip-adapter.github.io/)
* [IP-Adapter GitHub](https://github.com/tencent-ailab/IP-Adapter)
* [IP-Adapter Hugging Face](https://huggingface.co/h94/IP-Adapter)

![](/assets/sd-ecology/ip-adapter.png)


## Style Aligned Generation

<Accordion type="single" collapsible>
  <AccordionItem value="item-1">
    <AccordionTrigger>æ¨¡å‹è§£é‡Š</AccordionTrigger>
    <AccordionContent>
      > The target images attends to the reference image by applying AdaIN over their queries and keys using the
      reference queries and keys respectively. Then, we apply shared attention where the target features are updated by both the target values Vt and the reference values Vr.

      Style Align ä½œç”¨ä¸”ä»…ä½œç”¨äº UNet çš„ self-attention å±‚ï¼ˆè¡¥å……èƒŒæ™¯ï¼šUNet çš„ self-attention å±‚å‘ç”Ÿåœ¨ latent å›¾åƒå†…éƒ¨ï¼Œè€Œ cross-attention å‘ç”Ÿåœ¨å›¾åƒå’Œæ–‡å­— embeddings ä¹‹é—´ï¼‰ã€‚åœ¨åŒæ—¶ç”Ÿæˆå‚è€ƒå›¾åƒå’Œç›®æ ‡å›¾åƒæ—¶ï¼Œç›®æ ‡å›¾åƒçš„ self-attention å›å…±äº«ï¼ˆæ··å…¥ï¼‰å‚è€ƒå›¾åƒçš„æƒé‡ï¼Œä»è€Œè¾¾åˆ°é£æ ¼å¯¹é½çš„æ•ˆæœã€‚

      å…·ä½“æ–¹æ³•æ˜¯ï¼Œåœ¨ QKV çš„ç»“æ„ä¸­ï¼Œé€šè¿‡ AdaIN å°†å‚è€ƒå›¾åƒå’Œç›®æ ‡å›¾åƒçš„ Queryã€Key æ··åˆï¼Œç„¶åè®¡ç®—ç›®æ ‡å›¾åƒçš„ Valueã€‚é™¤æ­¤ä¹‹å¤–ï¼Œè‹¥æ˜¯å®Œå…¨å…±äº« self-attention åˆ™ä¼šä½¿ç”Ÿæˆå›¾åƒçš„ä¸°å¯Œæ€§ä¸‹é™ä¸”ä¼šå‡ºç°é¢œè‰²æ±¡æŸ“ç­‰é—®é¢˜ï¼Œè‹¥æ˜¯ä¸ä½¿ç”¨ AdaIN æ··åˆåˆ™å›¾åƒé£æ ¼çš„ä¸€è‡´æ€§ä¼šä¸‹é™ã€‚

      æ–‡ç« è¿˜è®¨è®ºäº†è¾“å…¥å‚è€ƒå›¾ï¼Œä½¿ç”¨ DDIM é€†å‘æ¨å€’æƒé‡ï¼Œä»è€Œä¿æŒé£æ ¼ä¸€è‡´æ€§çš„æ–¹æ³•ã€‚
    </AccordionContent>
  </AccordionItem>
</Accordion>


[Style Aligned Image Generation via Shared Attention](http://arxiv.org/abs/2312.02133)

https://style-aligned-gen.github.io
https://github.com/google/style-aligned/blob/main/style_aligned_sdxl.ipynb

![](/assets/sd-ecology/style-aligned.png)


## MagicAnimate

* [MagicAnimate å®˜ç½‘](https://showlab.github.io/magicanimate/)
* [MagicAnimate GitHub](https://github.com/magic-research/magic-animate)
* [MagicAnimate Hugging Face Space](https://huggingface.co/spaces/zcxu-eric/magicanimate)


## MotionCtrl

[MotionCtrl: A Unified and Flexible Motion Controller for Video Generation](http://arxiv.org/abs/2312.03641)

* [MotionCtrl](https://wzhouxiff.github.io/projects/MotionCtrl/)
* [TencentARC/MotionCtrl](https://github.com/TencentARC/MotionCtrl)

![](/assets/sd-ecology/motion-ctrl.png)

<video width="100%" controls>
  <source src="/assets/sd-ecology/motion-ctrl.mp4" type="video/mp4" />
</video>






